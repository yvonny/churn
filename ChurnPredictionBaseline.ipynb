{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline (3).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvonny/churn/blob/master/ChurnPredictionBaseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3_QkgnAeElN_"
      },
      "source": [
        "Paper: https://www.andrew.cmu.edu/user/lakoglu/pubs/StackOverflow-churn.pdf\n",
        "\n",
        "Description of datasets: https://ia800107.us.archive.org/27/items/stackexchange/readme.txt\n",
        "\n",
        "Site for download of datasets: https://archive.org/details/stackexchange\n",
        "\n",
        "This code has 6 steps\n",
        "\n",
        "1. Load StackOverflow datasets as dataframe\n",
        "2. Extract and label the datasets for each task\n",
        "3. Extract features for each task\n",
        "4. Analyze features\n",
        "5. Train models for each task with the features\n",
        "6. Quantify the importance of each feature category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BIq6tvSgGX_u"
      },
      "source": [
        "1. Load StackOverflow datasets as dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SkhHqE16EqWg",
        "colab": {}
      },
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install xmltodict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fsdakpOMEuhl",
        "colab": {}
      },
      "source": [
        "import xmltodict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0WX1fzL0Ezx5",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2r9tJIIxE1vI",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "gdrive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UIyjk-t9E3jo",
        "colab": {}
      },
      "source": [
        "def store_df_at_google_drive(fname, df, ftype=None):\n",
        "    s = io.StringIO()\n",
        "    if ftype == 'png':\n",
        "      uploaded = gdrive.CreateFile({'title': fname, 'parents':[{'id': 'root'}]})\n",
        "      uploaded.SetContentFile('%s.png'%(fname))\n",
        "      uploaded.Upload()\n",
        "      print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "    else:\n",
        "      df.to_csv(s)\n",
        "      uploaded = gdrive.CreateFile({'title': fname, 'parents':[{'id': 'root'}]})\n",
        "      uploaded.SetContentString(s.getvalue())\n",
        "      uploaded.Upload()\n",
        "      print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "def load_df_at_google_drive(fname):\n",
        "    file_list = gdrive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "    for file1 in file_list:\n",
        "        if (file1['title'] == fname):\n",
        "            downloaded = gdrive.CreateFile({'id': file1['id']})\n",
        "            s = io.StringIO(downloaded.GetContentString())\n",
        "            return pd.read_csv(s)\n",
        "    \n",
        "def load_dataset_from_google_drive(dir_id):\n",
        "    files = []\n",
        "    file_list = gdrive.ListFile({'q': \"'{}' in parents\".format(dir_id)}).GetList()\n",
        "    for f in file_list:\n",
        "      if f['title'] in ['Users.xml', 'Posts.xml','users_reduce.pkl', 'posts_reduce.pkl']:\n",
        "          print('  Load file: {}'.format(f['title']))\n",
        "          f_ = gdrive.CreateFile({'id': f['id']})\n",
        "          f_.GetContentFile(f['title'])\n",
        "          files.append(f['title'])\n",
        "    return files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_9rM193FeAn",
        "outputId": "0fd7bd41-2927-4d23-b0ec-4a2ada4f8b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "dfiles = load_dataset_from_google_drive('1Fp_7GDH_t7xfnU8aXeKrcBC54_nECOcu') "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Load file: users_reduce.pkl\n",
            "  Load file: posts_reduce.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdsPFIlqPRGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbh_OQyiGK2Z",
        "outputId": "4c0d5f11-cef5-4aa3-9d37-ef69c95380ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "users_df = pd.read_pickle(\"{}.pkl\".format('users_reduce'))   # shape: (992,110, 3)\n",
        "posts_df = pd.read_pickle(\"{}.pkl\".format('posts_reduce'))   # shape: (11,324,326, 10)\n",
        "\n",
        "users_df.shape, posts_df.shape   # Total dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((992110, 3), (11324326, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ugS0FTGWGhg9"
      },
      "source": [
        "2. Extract and label the datasets for each tasks\n",
        "\n",
        "You should extract the dataset for the period of the dataset: July 31, 2008 ~ July 31, 2012\n",
        "\n",
        "There are 2 tasks:\n",
        "\n",
        "A. After a user's K-th post, predict how likely it is that the user will churn\n",
        "\n",
        "B. After the T-th day from the account creation of a user, predict how likely it is that the user will churn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ztCnzaoPGQTJ",
        "outputId": "76c2c109-d4e7-4357-deb1-406bd040a2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def getIthOfPosts(posts):\n",
        "    print('getIthOfPosts')\n",
        "    posts.sort_values(by=['OwnerUserId', 'CreationDate'], inplace=True)\n",
        "    posts.reset_index(level=0, inplace=True)\n",
        "    posts['id_owner_time'] = posts.index\n",
        "    first_posts = posts.groupby('OwnerUserId')['id_owner_time'].min().to_frame()\n",
        "    tmp = posts.join(first_posts, on='OwnerUserId', how='inner', lsuffix='F', rsuffix='P')\n",
        "    posts['ith'] = tmp['id_owner_timeF'] - tmp['id_owner_timeP'] + 1\n",
        "    posts = posts.drop(['id_owner_time'], axis=1)\n",
        "    return posts\n",
        "\n",
        "# You should extract the dataset for the period of the dataset: July 31, 2008 ~  July 31, 2012\n",
        "start_time = pd.to_datetime('2008-07-31')\n",
        "end_time = pd.to_datetime('2012-07-31')\n",
        "end_time_2 = pd.to_datetime('2012-01-31')\n",
        "\n",
        "posts_df = posts_df[(posts_df['CreationDate'] >= start_time) & (posts_df['CreationDate'] <= end_time)]\n",
        "users_df = users_df[(users_df['CreationDate'] >= start_time) & (users_df['CreationDate'] <= end_time_2)]\n",
        "\n",
        "\n",
        "posts_df = getIthOfPosts(posts_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getIthOfPosts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "azQSCsXHHAza",
        "colab": {}
      },
      "source": [
        "# Dataset in Task 1\n",
        "#   Posts: Extract K posts of each user\n",
        "#   Users: Extract users who post at least K\n",
        "\n",
        "\n",
        "def getTask1Posts(posts, K):\n",
        "    tmp = posts[posts['ith'] == K]['OwnerUserId'].to_frame()\n",
        "    tmp = tmp.set_index('OwnerUserId')\n",
        "    tmp = posts[posts['OwnerUserId'].isin(tmp.index)]\n",
        "    return tmp[tmp['ith'] <= K]\n",
        "\n",
        "\n",
        "def getTask1Users(users, posts, K):\n",
        "    users['num_posts'] = posts.groupby('OwnerUserId')['OwnerUserId'].count()\n",
        "    users = users[users['num_posts'] >= K]\n",
        "    return users\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlsZBbM8ctQv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "b2f01b5e-71d2-40e0-a88b-de38ca924c9f"
      },
      "source": [
        "list_of_K = range(1, 21)\n",
        "users_of_task1, posts_of_task1 = {}, {}\n",
        "\n",
        "\n",
        "for K in list_of_K:\n",
        "    posts_of_task1[K] = getTask1Posts(posts_df, K)\n",
        "    users_of_task1[K] = getTask1Users(users_df, posts_df, K)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1e62ca3b1342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_K\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mposts_of_task1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTask1Posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposts_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0musers_of_task1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTask1Users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposts_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-5f9f17358162>\u001b[0m in \u001b[0;36mgetTask1Users\u001b[0;34m(users, posts, K)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetTask1Users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OwnerUserId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OwnerUserId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;34m\"\"\" Compute count of group, excluding missing values \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mgroup_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroup_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mcomp_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_group_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_compressed_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_compressed_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_compressed_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mping\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             group_index = get_group_index(all_labels, self.shape,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_compressed_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mping\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             group_index = get_group_index(all_labels, self.shape,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mlabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m_make_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 labels, uniques = algorithms.factorize(\n\u001b[0;32m--> 392\u001b[0;31m                     self.grouper, sort=self.sort)\n\u001b[0m\u001b[1;32m    393\u001b[0m                 \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, order, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    611\u001b[0m                                            \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                                            \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m                                            na_value=na_value)\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_factorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     uniques, labels = table.factorize(values, na_sentinel=na_sentinel,\n\u001b[0;32m--> 460\u001b[0;31m                                       na_value=na_value)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.factorize\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable._unique\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \"\"\"Convert the input to an array.\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OpHDgehj4gde",
        "colab": {}
      },
      "source": [
        "# Churn in Task 1\n",
        "#   Churners: Users who did not post for at least 6 months from their K-th post \n",
        "#   Stayers:  Users who created at least one post within the 6 months from their K-th post\n",
        "\n",
        "def prepareFeaturesTask1(users, posts, K):\n",
        "    tmp = posts[posts['ith']==K]['OwnerUserId'].to_frame()\n",
        "    tmp = tmp.set_index('OwnerUserId')\n",
        "    posts = posts[posts['OwnerUserId'].isin(tmp.index)]\n",
        "\n",
        "    posts_task = posts[posts['OwnerUserId'].isin(users.index)]\n",
        "    posts_Kth_time = posts_task[posts_task['ith']==K]\n",
        "    posts_Kth_time = posts_Kth_time.set_index('OwnerUserId')['CreationDate']\n",
        "    posts_deadline = posts_Kth_time + pd.tseries.offsets.DateOffset(months=6)\n",
        "    \n",
        "    posts_stayer = posts_task[posts_task['ith'] > K].groupby('OwnerUserId')['CreationDate'].min().to_frame()\n",
        "    posts_stayer = posts_stayer.merge(posts_deadline, on='OwnerUserId', how='left', suffixes=('_left', '_right'))\n",
        "    \n",
        "    posts_churner1 = posts_stayer[posts_stayer['CreationDate_left'] > posts_stayer['CreationDate_right']]\n",
        "    posts_churner1['is_churn'] = 1\n",
        "    posts_churner1 = posts_churner1[['is_churn']]\n",
        "    posts_stayer = posts_stayer[posts_stayer['CreationDate_left'] <= posts_stayer['CreationDate_right']]\n",
        "    posts_stayer['is_churn'] = 0    \n",
        "    posts_stayer = posts_stayer[['is_churn']]\n",
        "       \n",
        "    posts_churner2 = posts_task[posts_task['ith'] >= K].groupby('OwnerUserId').count()\n",
        "    posts_churner2 = posts_churner2[posts_churner2['CreationDate'] == 1][['CreationDate']]\n",
        "    posts_churner2['is_churn'] = 1\n",
        "    posts_churner2 = posts_churner2[['is_churn']]\n",
        "    \n",
        "    posts = pd.concat([posts_stayer, posts_churner1, posts_churner2])\n",
        "    posts = posts.rename(columns={'OwnerUserId': 'Id'})\n",
        "    users['is_churn'] = 0\n",
        "    users.update(posts)\n",
        "    return users\n",
        "\n",
        "features_of_task1 = {}\n",
        "\n",
        "for K in list_of_K:\n",
        "    features_of_task1[K] = prepareFeaturesTask1(users_of_task1[K], posts_df, K)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3V0x2GCZvr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ktdgsULZWIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Figure 1: Histogram of churning and staying users by post count (up to 20)\n",
        "\n",
        "num_churners = []\n",
        "num_stayers = []\n",
        "\n",
        "for K in list_of_K:\n",
        "  features = features_of_task1[K]\n",
        "  nums = list(features.groupby('is_churn')['is_churn'].count())\n",
        "  num_churners.append(nums[1])\n",
        "  num_stayers.append(nums[0])\n",
        "\n",
        "colorList=['g','r']\n",
        "y = np.array([num_stayers, num_churners])\n",
        "\n",
        "\n",
        "for i in range(y.shape[0]):\n",
        "  plt.bar(np.arange(y.shape[1]), y[i], bottom=np.sum(y[:i], axis=0), color=colorList[(i % len(colorList))])\n",
        "plt.legend(['stayer','churner'])\n",
        "plt.savefig('Figure1.png')\n",
        "# store_df_at_google_drive('Figure1',pd.DataFrame(), 'png')\n",
        "files.download('Figure1.png')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Ln3Q7trGg06",
        "colab": {}
      },
      "source": [
        "# Dataset in Task 2\n",
        "#   Users: Extract users who post at least 1\n",
        "#   Posts: Extract posts which create before T day from the account creation of the owner\n",
        "\n",
        "def getCreationDateOfOwner(users, posts):\n",
        "    posts['DataframeIndex'] = posts.index\n",
        "    posts['CreationDateOfOwner'] = posts.set_index('OwnerUserId')\\\n",
        "            .join(users, how='inner', rsuffix='OfOwner')\\\n",
        "            .set_index('DataframeIndex')['CreationDateOfOwner']\n",
        "    posts = posts.drop(['DataframeIndex'], axis=1)\n",
        "    return posts['CreationDateOfOwner']\n",
        "\n",
        "  \n",
        "def getTask2Posts(users, posts, T):\n",
        "    if 'CreationDateOfUser' not in posts.columns:\n",
        "        posts['CreationDateOfOwner'] = getCreationDateOfOwner(users, posts)\n",
        "    observation_deadline = posts['CreationDateOfOwner'] + pd.offsets.Day(T)\n",
        "    posts = posts[posts['CreationDate'] <= observation_deadline]\n",
        "    return posts\n",
        "  \n",
        "def getTask2Users(users, posts):\n",
        "    users['num_posts'] = posts.groupby('OwnerUserId')['OwnerUserId'].count()\n",
        "    users = users[users['num_posts'] >= 1]\n",
        "    return users\n",
        "  \n",
        "list_of_T = [7, 15, 30]\n",
        "users_of_task2 = {}\n",
        "posts_of_task2 = {}\n",
        "\n",
        "for T in list_of_T:\n",
        "    posts_of_task2[T] = getTask2Posts(users_df, posts_df, T)\n",
        "    users_of_task2[T] = getTask2Users(users_df, posts_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYIvRp-nY8q-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4KFrYJP0H8H8",
        "colab": {}
      },
      "source": [
        "# Churn in Task2\n",
        "#   Churners: Users who did not post for at least 6 months from T days after account creation\n",
        "#   Stayers:  Users who created at least one post within the 6 months from T days after account creation\n",
        "\n",
        "def prepareFeaturesTask2(users, posts, T=30):\n",
        "    if 'CreationDateOfUser' not in posts.columns:\n",
        "        posts['CreationDateOfOwner'] = getCreationDateOfOwner(users, posts)\n",
        "    users = getTask1Users(users, posts, K=1)\n",
        "    observe_deadline = posts['CreationDateOfOwner'] + pd.offsets.Day(T)\n",
        "    churn_deadline = observe_deadline + pd.tseries.offsets.DateOffset(months=6)\n",
        "    posts_observed = posts[(posts['CreationDate'] <= observe_deadline) & (posts['CreationDate'] >= posts['CreationDateOfOwner'])]\n",
        "    posts_after_observe = posts[(posts['CreationDate'] <= churn_deadline) & (posts['CreationDate'] > observe_deadline)]\n",
        "    label_df = users.reindex((posts_observed.groupby('OwnerUserId')['OwnerUserId'].count() > 0).index)\n",
        "    stayers = (posts_after_observe.groupby('OwnerUserId')['OwnerUserId'].count() > 0).index\n",
        "    churners = list(set(label_df.index) - set(stayers))\n",
        "    label_df['is_churn'] = 0.\n",
        "    label_df.loc[churners, 'is_churn'] = 1.\n",
        "    return label_df\n",
        "\n",
        "features_of_task2 = {}\n",
        "for T in list_of_T:\n",
        "    features_of_task2[T] = prepareFeaturesTask2(users_of_task2[T], posts_df, T)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tTUabuRXIMeh"
      },
      "source": [
        "3. Extract features for each task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qeu0qyZjIVaW"
      },
      "source": [
        "3-1. Temporal features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1BwDqBD4H_my",
        "colab": {}
      },
      "source": [
        "# Temporal features 1: gap1\n",
        "def getTimeGap1OfUser(users, posts):\n",
        "    creation_date_user = users['CreationDate']\n",
        "    creation_date_first_post = posts.groupby('OwnerUserId')['CreationDate'].min()\n",
        "    return (creation_date_first_post - creation_date_user).dt.total_seconds()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blqxv9rsIiFT",
        "colab": {}
      },
      "source": [
        "# Temporal features 2: gapK  (units: min)\n",
        "# k > 2\n",
        "def getTimeGapkOfPosts(posts, k):\n",
        "    date_1 = posts[posts['ith'] == (k-1)].sort_values('OwnerUserId')\n",
        "    date_2 = posts[posts['ith'] == k].sort_values('OwnerUserId')\n",
        "    date_2 = date_2.set_index('OwnerUserId')\n",
        "    date_1 = date_1.set_index('OwnerUserId')\n",
        "    result = (date_2['CreationDate'] - date_1['CreationDate']).dt.total_seconds() / 60  \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lpApw_8FMA8O",
        "colab": {}
      },
      "source": [
        "# Temporal features 3: last_gap (units : min)\n",
        "def getTimeLastGapOfPosts(posts):\n",
        "    last_posts = posts.groupby('OwnerUserId')['CreationDate'].max().to_frame()\n",
        "    tmp = posts.join(last_posts, on='OwnerUserId', how='inner', lsuffix='F', rsuffix='P')\n",
        "    tmp = tmp[tmp['CreationDateF'] < tmp['CreationDateP']].groupby('OwnerUserId')['CreationDateF'].max().to_frame()\n",
        "    return (last_posts['CreationDate'] - tmp['CreationDateF']).dt.total_seconds() / 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RpmdwUxkMFdq",
        "colab": {}
      },
      "source": [
        "# Temporal features 4: time_since_last_post (units: min)\n",
        "def getTimeSinceLastPost(users, posts, T):\n",
        "    last_post_date = posts.groupby('OwnerUserId')['CreationDate'].max()\n",
        "    creation_after_T_days_date = users['CreationDate'] + pd.offsets.Day(T)\n",
        "    return (creation_after_T_days_date - last_post_date).dt.total_seconds() / 60\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PhBuCzYXMQ4A",
        "colab": {}
      },
      "source": [
        "# Temporal features 5: mean_gap\n",
        "def getTimeMeanGap(posts):\n",
        "    last_post_date = posts.groupby('OwnerUserId')['CreationDate'].max()\n",
        "    first_post_date = posts.groupby('OwnerUserId')['CreationDate'].min()\n",
        "    num_posts = posts.groupby('OwnerUserId')['CreationDate'].count()\n",
        "    return (last_post_date - first_post_date).dt.total_seconds() / 60 / num_posts\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wUa-4pyI96fP",
        "colab": {}
      },
      "source": [
        "# Extract temporal features for task1\n",
        "for K in list_of_K:\n",
        "    features_of_task1[K]['gap1'] = getTimeGap1OfUser(users_of_task1[K], posts_of_task1[K])\n",
        "    for k in range(2, K+1):\n",
        "        features_of_task1[K]['gap{}'.format(k)] = getTimeGapkOfPosts(posts_of_task1[K], k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CgicxCHzBHs2",
        "colab": {}
      },
      "source": [
        "# Figure 2: Gap between posts\n",
        "#    For a user who churns, gap between consecutive posts keeps increasing. \n",
        "#    Gaps for those who stay are much lower, and stabilize around 20,000 minutes,\n",
        "#    indicating routine posting activity in every â‰ˆ2 weeks.\n",
        "clist = []\n",
        "slist = []\n",
        "subt = []\n",
        "for K in list_of_K:\n",
        "    subgroup = features_of_task1[K]\n",
        "    churners_gap = []\n",
        "    stayers_gap = []\n",
        "    for i in range(2, K+1):\n",
        "        gapK = 'gap{}'.format(i)\n",
        "        sum_gapK = list(subgroup.groupby('is_churn')[gapK].sum())\n",
        "        count_gapK = list(subgroup.groupby('is_churn')[gapK].count())\n",
        "        if len(sum_gapK) < 2:\n",
        "            break\n",
        "        churners_gap.append(sum_gapK[1] / count_gapK[1])\n",
        "        stayers_gap.append(sum_gapK[0] / count_gapK[0])\n",
        "    subt.append('K = %s'%K)\n",
        "    clist.append(churners_gap)\n",
        "    slist.append(stayers_gap)\n",
        "    \n",
        "    print(\"K={}\".format(K))\n",
        "    plt.plot(churners_gap, '-o', label='churner')\n",
        "    plt.plot(stayers_gap, '-o', label='stayer')\n",
        "    plt.legend()\n",
        "    plt.axis((0,20,0,15e4))\n",
        "    \n",
        "    plt.show()\n",
        "#     files.download('task1_{0}posts_{1}.png'.format(K,'TimeGap1OfUser'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQFQBkpbB6_D",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2, 2, 1)\n",
        "ax2 = fig.add_subplot(2, 2, 2)\n",
        "ax3 = fig.add_subplot(2, 2, 3)\n",
        "ax4 = fig.add_subplot(2, 2, 4)\n",
        "axlist = [ax1, ax2, ax3, ax4]\n",
        "for c, s, ax,t in zip(clist[1:], slist[1:], axlist, subt[1:]):\n",
        "    ax.plot(c, '-o', label='churner')\n",
        "    ax.plot(s, '-o', label='stayer')\n",
        "    ax.legend()\n",
        "    ax.axis((0,20,0,15e4))\n",
        "    ax.set_title(t)\n",
        "fig.subplots_adjust(wspace=1, hspace=1)\n",
        "plt.savefig('Task1_Figure2_1.png')\n",
        "store_df_at_google_drive('Task1_Figure2_1',pd.DataFrame(), 'png')\n",
        "# files.download('Task1_Figure2_1.png')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2, 2, 1)\n",
        "ax2 = fig.add_subplot(2, 2, 2)\n",
        "ax3 = fig.add_subplot(2, 2, 3)\n",
        "ax4 = fig.add_subplot(2, 2, 4)\n",
        "axlist = [ax1, ax2, ax3, ax4]\n",
        "for c, s, ax, t in zip(clist[-4:], slist[-4:], axlist, subt[-4:]):\n",
        "    ax.plot(c, '-o', label='churner')\n",
        "    ax.plot(s, '-o', label='stayer')\n",
        "    ax.legend()\n",
        "    ax.axis((0,20,0,15e4))\n",
        "    ax.set_title(t)\n",
        "fig.subplots_adjust(wspace=1, hspace=1)\n",
        "plt.savefig('Task1_Figure2_2.png')\n",
        "store_df_at_google_drive('Task1_Figure2_2',pd.DataFrame(), 'png')\n",
        "# files.download('Task1_Figure2_2.png')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JlWoElW9CFcV",
        "colab": {}
      },
      "source": [
        "# Extract temporal features for task2\n",
        "for T in list_of_T:\n",
        "    users, posts = users_of_task2[T], posts_of_task2[T]\n",
        "    features_of_task2[T]['gap1'] = getTimeGap1OfUser(users, posts)\n",
        "    features_of_task2[T]['last_gap'] = getTimeLastGapOfPosts(posts).fillna(features_of_task2[T]['gap1'])\n",
        "    #features_of_task2[T]['last_gap'] = getTimeLastGapOfPosts(posts).fillna(0)\n",
        "    features_of_task2[T]['time_since_last_post'] = getTimeSinceLastPost(users, posts, T)\n",
        "    features_of_task2[T]['mean_gap'] = getTimeMeanGap(posts)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rB7E22Q4MSWR"
      },
      "source": [
        "3-2. Frequency features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wpECyr9kMTvJ",
        "colab": {}
      },
      "source": [
        "# Frequency features 1: num_answers\n",
        "# Frequency features 2: num_questions\n",
        "def getNumAnswers(posts):\n",
        "    answers = posts[posts['PostTypeId'] == 2]\n",
        "    return answers.groupby('OwnerUserId')['OwnerUserId'].count()\n",
        "\n",
        "def getNumQuestions(posts):\n",
        "    questions = posts[posts['PostTypeId'] == 1]\n",
        "    return questions.groupby('OwnerUserId')['OwnerUserId'].count()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsks_ldVUaQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KqmIPayXNHqY",
        "colab": {}
      },
      "source": [
        "# Frequency features 3: ans_ques_ratio\n",
        "def getAnsQuesRatio(num_answers, num_questions):\n",
        "    # Use Laplace Smoothing\n",
        "    return (num_answers + 1) / (num_questions + 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PNWqcYeONJvE",
        "colab": {}
      },
      "source": [
        "# Frequency features 4: num_posts\n",
        "def getNumPosts(posts):\n",
        "    return posts.groupby('OwnerUserId')['OwnerUserId'].count().astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jRcG-juDigR",
        "colab": {}
      },
      "source": [
        "# Extract frequency features of task1\n",
        "for K in list_of_K:\n",
        "    users, posts = users_of_task1[K], posts_of_task1[K]\n",
        "    features_of_task1[K]['num_answers'] = getNumAnswers(posts)\n",
        "    features_of_task1[K]['num_questions'] = getNumQuestions(posts)\n",
        "    features_of_task1[K] = features_of_task1[K].fillna({'num_answers':0, 'num_questions':0})\n",
        "    features_of_task1[K]['ans_que_ratio'] = \\\n",
        "        getAnsQuesRatio(features_of_task1[K]['num_answers'], features_of_task1[K]['num_questions'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pHo_ds2wFRWB",
        "colab": {}
      },
      "source": [
        "# Extract frequency features of task2\n",
        "for T in list_of_T:\n",
        "    users, posts = users_of_task2[T], posts_of_task2[T]\n",
        "    features_of_task2[T]['num_answers'] = getNumAnswers(posts)\n",
        "    features_of_task2[T]['num_questions'] = getNumQuestions(posts)\n",
        "    features_of_task2[T] = features_of_task2[T].fillna({'num_answers':0,'num_questions':0})\n",
        "    features_of_task2[T]['ans_que_ratio'] = \\\n",
        "        getAnsQuesRatio(features_of_task2[T]['num_answers'], features_of_task2[T]['num_questions'])\n",
        "    features_of_task2[T]['num_posts'] = getNumPosts(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2IwckKPVekk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ItDHgLi6FtEA",
        "colab": {}
      },
      "source": [
        "# Figure 3: # Answers vs Churn probability\n",
        "#    The probability of churning for a user decreases the more answers s/he provides.\n",
        "#    It is even lower if s/he asks more questions alongside.\n",
        "\n",
        "min_num_users = 50\n",
        "for T in list_of_T:\n",
        "    task2 = features_of_task2[T]\n",
        "    for num_que_ask in range(5):\n",
        "        subgroup = task2[task2['num_questions'] == num_que_ask]\n",
        "        churn_probs = []\n",
        "        num_answers = list(set(subgroup['num_answers']))\n",
        "        num_answers.sort()\n",
        "        for num_ans in num_answers:\n",
        "            subsubgroup = subgroup[subgroup['num_answers'] == num_ans]\n",
        "            prob = sum(subsubgroup['is_churn']) / subsubgroup.shape[0]\n",
        "            if subsubgroup.shape[0] >= min_num_users:\n",
        "                churn_probs.append((num_ans, prob))\n",
        "\n",
        "        plt.plot([np.log10(x[0]+1) for x in churn_probs],\n",
        "                 [np.log10(x[1]+0.01) for x in churn_probs],\n",
        "                 '-o',\n",
        "                 label='{} ques asked'.format(num_que_ask))\n",
        "    print(\"# Answers vs Churn probability\")\n",
        "    plt.legend()\n",
        "    plt.axis((0,2,-2,0))\n",
        "    \n",
        "    plt.savefig('Task2_T{}_churn_prob.png'.format(T))\n",
        "    store_df_at_google_drive('Task2_T{}_churn_prob'.format(T), pd.DataFrame(),'png')\n",
        "    \n",
        "    files.download('Task2_T{}_churn_prob.png'.format(T))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HYDXzIXLNN58"
      },
      "source": [
        "3-3. Knowledge features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W1GRvX0PRk_",
        "colab": {}
      },
      "source": [
        "# For the fast extraction, prepare questions x answers\n",
        "def preprocessForKnowledgeFeaturesForTask1(users, posts, all_posts):\n",
        "    answers = posts[posts['PostTypeId'] == 2]\n",
        "    questions = posts[posts['PostTypeId'] == 1]\n",
        "    all_answers = all_posts[all_posts['PostTypeId'] == 2]\n",
        "    all_questions = all_posts[all_posts['PostTypeId'] == 1]\n",
        "\n",
        "    qnta = all_answers.set_index('ParentId')\\\n",
        "        .join(questions, how='inner',\\\n",
        "              lsuffix='A', rsuffix='Q')\n",
        "    tqna = answers.set_index('ParentId')\\\n",
        "        .join(all_questions, how='inner',\\\n",
        "              lsuffix='A', rsuffix='Q')\n",
        "    return answers, questions, qnta, tqna"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-D6rXdOa4ms",
        "colab": {}
      },
      "source": [
        "# For the fast extraction, prepare questions x answers\n",
        "def preprocessForKnowledgeFeaturesForTask2(users, posts):\n",
        "    answers = posts[posts['PostTypeId'] == 2]\n",
        "    questions = posts[posts['PostTypeId'] == 1]\n",
        "    qna = answers\\\n",
        "        .set_index('ParentId').join(questions, how='inner',\\\n",
        "                                    lsuffix='A', rsuffix='Q')\n",
        "    return answers, questions, qna, qna"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s7c9nOpPNLdO",
        "colab": {}
      },
      "source": [
        "# Knowledge features 1: accepted_answerer_rep\n",
        "def getRepOfAcceptedAnswerer(users, answers, questions, qnta, tqna):\n",
        "    reputations = users.loc[:, ['Reputation']]\n",
        "    rep_accepted_ans = qnta[qnta['AcceptedAnswerIdQ'] == qnta['IdA']]\\\n",
        "        .set_index('OwnerUserIdA')\\\n",
        "        .join(reputations, how='inner')\\\n",
        "        .groupby('OwnerUserIdQ')['Reputation'].mean()\n",
        "    return rep_accepted_ans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oVLRFX12NPCZ",
        "colab": {}
      },
      "source": [
        "# Knowledge features 2: max_rep_answerer \n",
        "def getMaxRepAmongAnswerer(users, answers, questions, qnta, tqna):\n",
        "    reputations = users.loc[:, ['Reputation']]\n",
        "    rep_max_ans = qnta.set_index('OwnerUserIdA')\\\n",
        "        .join(reputations, how='inner')\\\n",
        "        .groupby('OwnerUserIdQ')['Reputation'].max()\n",
        "    return rep_max_ans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h7F5YoZ7NQUk",
        "colab": {}
      },
      "source": [
        "# Knowledge features 3: num_que_answered\n",
        "def getNumQueAnswered(users, answers, questions, qnta, tqna):\n",
        "    # number of questions posted by the user that got answered\n",
        "    #questions = posts[posts['PostTypeId'] == 1]\n",
        "    answered_questions = questions[questions['AnswerCount'] > 0]\n",
        "    return answered_questions.groupby('OwnerUserId')['AnswerCount'].count()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3vZxSTm5NRPx",
        "colab": {}
      },
      "source": [
        "# Knowledge features 4: time_for_first_ans , unit : mins\n",
        "def getTimeForFirstAns(users, answers, questions, qnta, tqna):\n",
        "    tmp =  qnta[qnta['CreationDateQ'] < qnta['CreationDateA']]\n",
        "    tmp['time_for_ans'] = (tmp['CreationDateA'] - tmp['CreationDateQ']).dt.total_seconds() / 60\n",
        "    questions['time_for_first_ans'] = tmp.groupby(by=tmp.index)['time_for_ans'].min()\n",
        "    return questions.groupby('OwnerUserId')['time_for_first_ans'].mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-tFQfJQNSe0",
        "colab": {}
      },
      "source": [
        "# Knowledge features 5: rep_questioner\n",
        "def getAvgRepOfQuestioner(users, answers, questions, qnta, tqna):\n",
        "    # Avg. reputation of the user whose question was answered\n",
        "    reputations = users.loc[:, ['Reputation']]\n",
        "    rep_accepted_ans = tqna.set_index('OwnerUserIdQ')\\\n",
        "        .join(reputations, how='inner')\\\n",
        "        .groupby('OwnerUserIdA')['Reputation'].mean()\n",
        "    return rep_accepted_ans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DfugZxXNTeC",
        "colab": {}
      },
      "source": [
        "# Knowledge features 6: rep_answerers\n",
        "def getAvgRepOfAnswerer(users, answers, questions, qnta, tqna):\n",
        "    # Avg. reputation of the users who answered the question\n",
        "    reputations = users.loc[:, ['Reputation']]\n",
        "    rep_accepted_ans = qnta.set_index('OwnerUserIdA')\\\n",
        "        .join(reputations, how='inner')\\\n",
        "        .groupby('OwnerUserIdQ')['Reputation'].mean()\n",
        "    return rep_accepted_ans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9sD-x4HhNUyX",
        "colab": {}
      },
      "source": [
        "# Knowledge features 7: rep_co_answerers\n",
        "def getAvgRepOfCoAnswerer(users, answers, questions, qnta, tqna):\n",
        "    reputations = users.loc[:, ['Reputation']]    \n",
        "    rep_ans = answers.set_index('OwnerUserId')\\\n",
        "        .join(reputations, how='inner')\\\n",
        "        .set_index('ParentId')\\\n",
        "        .join(questions, how='inner', lsuffix='A', rsuffix='Q')\n",
        "    avg_rep_ans = rep_ans.groupby(by=rep_ans.index)['Reputation'].mean()\n",
        "    rep_co_answerer = answers.set_index('ParentId')\\\n",
        "        .join(avg_rep_ans, how='inner')\\\n",
        "        .set_index('OwnerUserId')\n",
        "    return rep_co_answerer.groupby(by=rep_co_answerer.index)['Reputation'].mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YBNqrO0jNWHJ",
        "colab": {}
      },
      "source": [
        "# Knowledge features 8: num_answers_recvd\n",
        "def getAvgNumAnsReceived(users, answers, questions, qnta, tqna):\n",
        "    #questions = posts[posts['PostTypeId'] == 1]\n",
        "    return questions.fillna({'AnswerCount': 0}).groupby('OwnerUserId')['AnswerCount'].mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BlYoLY17HvpP",
        "colab": {}
      },
      "source": [
        "# Extract knowledge features of task 1\n",
        "for K in list_of_K:\n",
        "    print(\"Extract knowledge features of task1(K=\",K,\")\")\n",
        "    users, posts = users_of_task1[K], posts_of_task1[K]\n",
        "    answers, questions, qnta, tqna = preprocessForKnowledgeFeaturesForTask1(users, posts, posts_df)\n",
        "    features_of_task1[K]['accepted_answerer_rep'] = getRepOfAcceptedAnswerer(users, answers, questions,  qnta, tqna)\n",
        "    features_of_task1[K]['max_rep_answerer'] = getMaxRepAmongAnswerer(users, answers, questions,  qnta, tqna)\n",
        "    features_of_task1[K]['num_que_answered'] = getNumQueAnswered(users, answers, questions,  qnta, tqna)\n",
        "    features_of_task1[K]['time_for_first_ans'] = getTimeForFirstAns(users, answers, questions, qnta, tqna)\n",
        "    features_of_task1[K]['rep_questioner'] = getAvgRepOfQuestioner(users, answers, questions, qnta, tqna)\n",
        "    features_of_task1[K]['rep_answerers'] = getAvgRepOfAnswerer(users, answers, questions, qnta, tqna)\n",
        "    features_of_task1[K]['rep_co_answerers'] = getAvgRepOfCoAnswerer(users, answers, questions, qnta, tqna)\n",
        "    features_of_task1[K]['num_answers_recvd'] = getAvgNumAnsReceived(users, answers, questions, qnta, tqna)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qSsmpTI_L3Gr",
        "colab": {}
      },
      "source": [
        "for T in list_of_T:\n",
        "    print(\"Extract knowledge features of task2(T=)\",T,\")\")\n",
        "    users, posts = users_of_task2[T], posts_of_task2[T]\n",
        "    answers, questions, qna, qna1 = preprocessForKnowledgeFeaturesForTask2(users, posts)\n",
        "    features_of_task2[T]['accepted_answerer_rep'] = getRepOfAcceptedAnswerer(users, answers, questions, qna, qna1)\n",
        "    features_of_task2[T]['max_rep_answerer'] = getMaxRepAmongAnswerer(users, answers, questions, qna, qna1)\n",
        "    features_of_task2[T]['num_que_answered'] = getNumQueAnswered(users, answers, questions, qna, qna1)\n",
        "    features_of_task2[T]['time_for_first_ans'] = getTimeForFirstAns(users, answers, questions, qna, qna1)\n",
        "    features_of_task2[T]['rep_questioner'] = getAvgRepOfQuestioner(users, answers, questions, qna, qna1)\n",
        "    features_of_task2[T]['rep_answerers'] = getAvgRepOfAnswerer(users, answers, questions, qna, qna1)\n",
        "    features_of_task2[T]['rep_co_answerers'] = getAvgRepOfCoAnswerer(users, answers, questions, qna, qna1)\n",
        "    features_of_task2[T]['num_answers_recvd'] = getAvgNumAnsReceived(users, answers, questions, qna, qna1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ_U_61eaYov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFqcmT0UdEuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Figure 4: K vs Time taken for the first answer to arrive\n",
        "#  The more the time taken for a user to receive an answer, \n",
        "#  the lesser the satisfaction level and the more the chances of churning.\n",
        "churners_time = []\n",
        "stayers_time = []\n",
        "for K in list_of_K:\n",
        "    subgroup = features_of_task1[K]\n",
        "    subgroup = subgroup.fillna({'time_for_first_ans': -1})\n",
        "    subgroup = subgroup[subgroup['time_for_first_ans'] >= 0]\n",
        "    churners = subgroup[subgroup['is_churn'] == 1]\n",
        "    stayers = subgroup[subgroup['is_churn'] == 0]\n",
        "    churners_time.append(churners['time_for_first_ans'].mean())\n",
        "    stayers_time.append(stayers['time_for_first_ans'].mean())\n",
        "    \n",
        "\n",
        "print(churners_time)\n",
        "print(stayers_time)\n",
        "\n",
        "plt.plot(churners_time, '-o', label='churner')\n",
        "plt.plot(stayers_time, '-o', label='stayer')\n",
        "plt.legend()\n",
        "# plt.axis((0,20,8e3,22e3))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9MT48B2mVZkQ",
        "colab": {}
      },
      "source": [
        "# Figure 4: K vs Time taken for the first answer to arrive\n",
        "#  The more the time taken for a user to receive an answer, \n",
        "#  the lesser the satisfaction level and the more the chances of churning.\n",
        "\n",
        "churners_time = []\n",
        "stayers_time = []\n",
        "for K in list_of_K:\n",
        "    subgroup = features_of_task1[K]\n",
        "    churners = subgroup[subgroup['is_churn'] == 1][subgroup['time_for_first_ans'] >= 0] \n",
        "    stayers = subgroup[subgroup['is_churn'] == 0][subgroup['time_for_first_ans'] >= 0]\n",
        "    churners_time.append(churners['time_for_first_ans'].mean())\n",
        "    stayers_time.append(stayers['time_for_first_ans'].mean())\n",
        "    \n",
        "\n",
        "plt.plot(churners_time, '-o', label='churner')\n",
        "plt.plot(stayers_time, '-o', label='stayer')\n",
        "plt.legend()\n",
        "# plt.axis((0,20,8e3,22e3))\n",
        "plt.savefig('Task1_Figure4.png')\n",
        "store_df_at_google_drive('Task1_Figure4',pd.DataFrame(),'png')\n",
        "# files.download('Task1_Figure4.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a6xXsmwjf8I2"
      },
      "source": [
        "Implement the other features yourself!!\n",
        "\n",
        "3-4. Speed features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22HdT-nTdX66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Speed features 1: answering_speed\n",
        "def getAnsweringSpeed(questions_df, answers_df):\n",
        "    answers_df = posts[posts['PostTypeId'] == 2]\n",
        "    questions_df = posts[posts['PostTypeId'] == 1]\n",
        "    \n",
        "    qna = answers_df.set_index('ParentId')\\\n",
        "        .join(questions_df, how='inner', lsuffix='A', rsuffix='Q')\n",
        "    qna = qna[qna['CreationDateQ'] < qna['CreationDateA']]\n",
        "    qna['time_for_ans'] = (qna['CreationDateA'] - qna['CreationDateQ']).dt.total_seconds() // 60\n",
        "    return 1 / qna.groupby('OwnerUserIdA')['time_for_ans'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slE3i5qidZ0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = posts_df[posts_df['PostTypeId'] == 2]\n",
        "for K in list_of_K:\n",
        "  questions = posts_of_task1[K]\n",
        "  questions = [questions['PostTypeId'] == 1]\n",
        "  features_of_task1[K]['answering_speed'] = getAnsweringSpeed(questions, answers)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpDjo9t2dbxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for T in list_of_T:\n",
        "  posts = posts_of_task2[T]\n",
        "  questions = posts[posts['PostTypeId'] == 1]\n",
        "  answers = posts[posts['PostTypeId'] == 2]\n",
        "  features_of_task2[T]['answering_speed'] = getAnsweringSpeed(questions, answers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5vU5RmbdgVi",
        "colab_type": "text"
      },
      "source": [
        "3-5. Quality features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ycywpUdmIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quality features 1: ans_score\n",
        "# Quality features 2: que_score\n",
        "def getScoreOfAnswers(posts):\n",
        "    answers = posts[posts['PostTypeId'] == 2]\n",
        "    return answers.groupby('OwnerUserId')['Score'].mean()\n",
        "\n",
        "def getScoreOfQuestions(posts):\n",
        "    questions = posts[posts['PostTypeId'] == 1]\n",
        "    return questions.groupby('OwnerUserId')['Score'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noZWGHPUdnMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for K in list_of_K:\n",
        "  posts = posts_of_task1[K]\n",
        "  features_of_task1[K]['score_of_answers'] = getScoreOfAnswers(posts)\n",
        "  features_of_task1[K]['score_of_questions'] = getScoreOfQuestions(posts) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM21H5-7doZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for T in list_of_T:\n",
        "  posts = posts_of_task2[T]\n",
        "  features_of_task2[T]['score_of_answers'] = getScoreOfAnswers(posts)\n",
        "  features_of_task2[T]['score_of_questions'] = getScoreOfQuestions(posts) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38OjMMJxdh1F",
        "colab_type": "text"
      },
      "source": [
        "3-6. Consistency features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um_dolBCdsGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Consistency features 1: ans_stddev\n",
        "# Consistency features 2: que_stddev\n",
        "def getStdevOfScoresOfAnswers(posts):\n",
        "    answers = posts[posts['PostTypeId'] == 2]\n",
        "    return answers.groupby('OwnerUserId')['Score'].std()\n",
        "\n",
        "def getStdevOfScoresOfQuestions(posts):\n",
        "    questions = posts[posts['PostTypeId'] == 1]\n",
        "    return questions.groupby('OwnerUserId')['Score'].std()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CROpFhvldttr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for K in list_of_K:\n",
        "  posts = posts_of_task1[K]\n",
        "  features_of_task1[K]['stdev_of_answers'] = getStdevOfScoresOfAnswers(posts)\n",
        "  features_of_task1[K]['stdev_of_questions'] = getStdevOfScoresOfQuestions(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X4cPQdqduok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for K in list_of_T:\n",
        "  posts = posts_of_task2[T]\n",
        "  features_of_task2[T]['stdev_of_answers'] = getStdevOfScoresOfAnswers(posts)\n",
        "  features_of_task2[T]['stdev_of_questions'] = getStdevOfScoresOfQuestions(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOeu-6T1di7a",
        "colab_type": "text"
      },
      "source": [
        "3-7. Gratitude features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Oa5rn91dv56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gratitude features 1: ans_comments\n",
        "# Gratitude features 2: que_comments\n",
        "def getAvgNumOfCommentsOfAnswers(posts):\n",
        "    answers = posts[posts['PostTypeId'] == 2]\n",
        "    return answers.groupby('OwnerUserId')['CommentCount'].mean()\n",
        "\n",
        "def getAvgNumOfCommentsOfQuestions(posts):\n",
        "    questions = posts[posts['PostTypeId'] == 1]\n",
        "    return questions.groupby('OwnerUserId')['CommentCount'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxkbIS0HdxUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for K in list_of_K:\n",
        "  posts = posts_of_task1[K]\n",
        "  features_of_task1[K]['avg_num_comments_of_answers'] = getAvgNumOfCommentsOfAnswers(posts)\n",
        "  features_of_task1[K]['avg_num_comments_of_questions'] = getAvgNumOfCommentsOfQuestions(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avCn90nzdx49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for K in list_of_T:\n",
        "  posts = posts_of_task2[T]\n",
        "  features_of_task2[T]['avg_num_comments_of_answers'] = getAvgNumOfCommentsOfAnswers(posts)\n",
        "  features_of_task2[T]['avg_num_comments_of_questions'] = getAvgNumOfCommentsOfQuestions(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0rI4JQJdj1H",
        "colab_type": "text"
      },
      "source": [
        "3-8. Competitiveness features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETQrUE4ddzjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Competitiveness features 1: relative_rank_pos --> Strange..\n",
        "def getRelativeRankPos(posts):\n",
        "    # average of total # of answers for a question divided by the rank of userâ€™s answer\n",
        "    answers_df = posts[posts['PostTypeId'] == 2]\n",
        "    ans_rank = answers_df.groupby('ParentId')['Score'].rank(method='average')\n",
        "    ans_count = answers_df.groupby('ParentId')['Score'].transform('count')\n",
        "#     answers_copy = answers_df.copy()\n",
        "#     answers_copy['RelRankPos'] =  ans_count / ans_rank\n",
        "    answers_copy = pd.DataFrame({\n",
        "        'OwnerUserId': answers_df['OwnerUserId'],\n",
        "        'RelRankPos': ans_count / ans_rank,\n",
        "    })\n",
        "    return answers_copy.groupby('OwnerUserId')['RelRankPos'].mean()\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G19Fl9abd08J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for K in list_of_K:\n",
        "  posts = posts_of_task1[K]\n",
        "  features_of_task1[K]['relative_rank_pos'] = getRelativeRankPos(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x8PcTPzd19o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for T in list_of_T:\n",
        "  posts = posts_of_task2[T]\n",
        "  features_of_task2[T]['relative_rank_pos'] = getRelativeRankPos(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9rHPGLPdknd",
        "colab_type": "text"
      },
      "source": [
        "3-9. Content features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMXVOu_kd3Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Content features 1: ans_length\n",
        "# Content features 2: que_length\n",
        "    # Length is the word counts\n",
        "def getAvgLengthOfAnswers(posts):\n",
        "    answers = posts[posts['PostTypeId'] == 2]\n",
        "    if 'BodyWordNum' in posts.columns:\n",
        "        return answers.groupby('OwnerUserId')['BodyWordNum'].mean()\n",
        "    return answers.groupby('OwnerUserId')['Body'].apply(lambda r: r.str.split().str.len().mean())\n",
        "\n",
        "def getAvgLengthOfQuestions(posts):\n",
        "    questions = posts[posts['PostTypeId'] == 1]\n",
        "    if 'BodyWordNum' in posts.columns:\n",
        "        return questions.groupby('OwnerUserId')['BodyWordNum'].mean()\n",
        "    return questions.groupby('OwnerUserId')['Body'].apply(lambda r: r.str.split().str.len().mean())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCJ5tURPd4SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for K in list_of_K:\n",
        "  posts = posts_of_task1[K]\n",
        "  features_of_task1[K]['avg_length_of_answers'] = getAvgLengthOfAnswers(posts)\n",
        "  features_of_task1[K]['avg_length_of_questions'] = getAvgLengthOfQuestions(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAwkKdgGd5ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for T in list_of_T:\n",
        "  posts = posts_of_task2[T]\n",
        "  features_of_task2[T]['avg_length_of_answers'] = getAvgLengthOfAnswers(posts)\n",
        "  features_of_task2[T]['avg_length_of_questions'] = getAvgLengthOfQuestions(posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dudtEkMMr7O",
        "colab": {}
      },
      "source": [
        "# Store the whole features of task1 to Google Drive\n",
        "for K in list_of_K:\n",
        "    store_df_at_google_drive('task1_{}posts_features.csv'.format(K), features_of_task1[K])\n",
        "#     features_of_task1[K].to_pickle('task1_{}posts_important_features.pkl'.format(K))\n",
        "#     features_of_task1[K].to_csv('task1_{}posts_important_features.csv'.format(K))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kh4gc3g0NDI-",
        "colab": {}
      },
      "source": [
        "for T in list_of_T:\n",
        "    store_df_at_google_drive('task2_{}posts_features.csv'.format(T), features_of_task2[T])\n",
        "    #features_of_task2[T].to_pickle('task2_{}days_important_features.pkl'.format(T))\n",
        "    #features_of_task2[T].to_csv('task2_{}days_important_features.csv'.format(T))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fhh-YaDUas2l"
      },
      "source": [
        "5. Train models for each tasks with the features\n",
        "\n",
        "    1. Decision Tree\n",
        "    2. SVM (Linear)\n",
        "    3. SVM (RBF)\n",
        "    4. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrB8-FxveR-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load features of task1\n",
        "# You can change the runtime to use GPU. It means you should load the features which you stored\n",
        "features_of_task1 = {}\n",
        "list_of_K = range(1, 21)\n",
        "for K in list_of_K:\n",
        "  features_of_task1[K] = load_df_at_google_drive('task1_{}posts_features.csv'.format(K))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPoRaggteTIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load features of task2\n",
        "# You can change the runtime to use GPU. It means you should load the features which you stored\n",
        "features_of_task2 = {}\n",
        "list_of_T = [7, 15, 30]\n",
        "for T in list_of_T:\n",
        "  features_of_task2[T] = load_df_at_google_drive('task2_{}posts_features.csv'.format(T))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CR4RcZp8dZFe",
        "colab": {}
      },
      "source": [
        "def fill_nan(features):\n",
        "    if 'time_for_first_ans' in features.columns and np.isnan(features['time_for_first_ans']).sum(0):\n",
        "        features['time_for_first_ans'] = 1 / features['time_for_first_ans']\n",
        "        features['time_for_first_ans'] = features['time_for_first_ans'].replace([np.nan], 0)\n",
        "    fill_constants = {\n",
        "        'accepted_answerer_rep': 0,\n",
        "        'max_rep_answerer': 0,\n",
        "        'num_que_answered': 0, \n",
        "        'rep_questioner': 0,\n",
        "        'rep_answerers': 0,\n",
        "        'rep_co_answerers': 0,\n",
        "        'num_answers_recvd': 0,\n",
        "        'answering_speed': 0,\n",
        "        'score_of_answers': 0,\n",
        "        'score_of_questions': 0,\n",
        "        'stdev_of_answers': 0,\n",
        "        'stdev_of_questions': 0,\n",
        "        'avg_num_comments_of_answers': 0,\n",
        "        'avg_num_comments_of_questions': 0,\n",
        "        'relative_rank_pos': 1,\n",
        "        'avg_length_of_answers': 0,\n",
        "        'avg_length_of_questions': 0,\n",
        "    }\n",
        "    return features.fillna(fill_constants)\n",
        "                                                                         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b0d6jNmw2ipN",
        "colab": {}
      },
      "source": [
        "for K in list_of_K:\n",
        "    print(\"Fill NaN of task1(K=\",K,\")\")\n",
        "    features_of_task1[K] = fill_nan(features_of_task1[K])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ObxxJXT32irv",
        "colab": {}
      },
      "source": [
        "for T in list_of_T:\n",
        "    print(\"Fill NaN of task2(T=)\",T,\")\")\n",
        "    features_of_task2[T] = fill_nan(features_of_task2[T])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVaX6ZXHBJUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda=9.0.176-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-uyAK1QBO-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huE6FTd0_3q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install thundersvm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZM9rDE9WO7e",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.svm import SVC\n",
        "from thundersvm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "\n",
        "max_iter=1e2\n",
        "\n",
        "def LogisticRegression_(*arg, **kwarg):\n",
        "    kwarg['max_iter'] = max_iter\n",
        "    kwarg['solver'] = 'saga'\n",
        "    kwarg['n_jobs'] = 8\n",
        "    return LogisticRegression(*arg, **kwarg)\n",
        "\n",
        "def SVC_rbf(*arg, **kwarg):\n",
        "#     kwarg['max_iter'] = max_iter\n",
        "    kwarg['kernel'] = 'rbf'\n",
        "#     kwarg['n_jobs'] = 8\n",
        "    return SVC(*arg, **kwarg)\n",
        "\n",
        "def SVC_linear(*arg, **kwarg):\n",
        "#     kwarg['max_iter'] = max_iter\n",
        "    kwarg['kernel'] = 'linear'\n",
        "#     kwarg['n_jobs'] = 8\n",
        "    return SVC(*arg, **kwarg)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUFUNbuvD85E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pmEBV3SA9fg6",
        "colab": {}
      },
      "source": [
        "def learn_model(data, train_features, target='is_churn', model=DecisionTreeClassifier, seed=seed):\n",
        "    X = data[train_features]\n",
        "    y = data[target]\n",
        "    print(model.__name__)\n",
        "        \n",
        "    ### 10-fold cross validation ###\n",
        "    acc_list = []\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        ### Under-sampling ###\n",
        "        churners = y_train[y_train == 1].index\n",
        "        stayers = y_train[y_train == 0].index\n",
        "        n_churn = len(churners)\n",
        "        n_stay = len(stayers)\n",
        "        print('churn : {}, stay : {}'.format(n_churn, n_stay))\n",
        "        if n_churn > n_stay:\n",
        "            churners = np.random.choice(churners, n_stay, replace=False)\n",
        "        else:\n",
        "            stayers = np.random.choice(stayers, n_churn, replace=False)\n",
        "        print('after sampling : churn : {}, stay : {}'.format(len(churners),len(stayers))) \n",
        "        train_index = np.array(list(churners) + list(stayers))\n",
        "        X_train, y_train = X.reindex(train_index), y.reindex(train_index)\n",
        "\n",
        "        ### Learn Model ###\n",
        "        start_time= time.time()\n",
        "        mdl = model().fit(X_train, y_train)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
        "        pred = mdl.predict(X_test)\n",
        "        acc = (pred == y_test)\n",
        "        acc_list.append(sum(acc)*100/len(acc))\n",
        "    return acc_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs4HUTmAC5Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_df = pd.DataFrame()\n",
        "\n",
        "# acc_df.loc[len(acc_df)][0] = [0]\n",
        "# acc_df.set_value(len(acc_df),'DT',1)\n",
        "# acc_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QjrE1aqQWO9t",
        "colab": {}
      },
      "source": [
        "# Table 2: Performance on Task 1\n",
        "\n",
        "drop_user_columns = ['Reputation', 'CreationDate', 'LastAccessDate', 'num_posts']\n",
        "\n",
        "models = [SVC_rbf, SVC_linear, DecisionTreeClassifier, LogisticRegression_]\n",
        "# models = [LogisticRegression_, SVC]\n",
        "for i in range(len(models)):\n",
        "# for i in range(2):\n",
        "# i=1\n",
        "  model = models[i]\n",
        "  for K in list_of_K:\n",
        "    stime = time.time()\n",
        "    print('Task 1,model={}, K={}, start : {}'.format(i,K, stime))\n",
        "    print(features_of_task1[K].columns )\n",
        "    train_features = [col for col in features_of_task1[K].columns \n",
        "                      if col not in drop_user_columns + ['is_churn']]\n",
        "    print(train_features)\n",
        "    acc_list = learn_model(features_of_task1[K], train_features, model=model)\n",
        "    acc_df.set_value(K,i,np.mean(acc_list))\n",
        "    print('Accuracy: {}'.format(np.mean(acc_list)))\n",
        "    print('    for each folds: {}'.format(acc_list))\n",
        "    print('end : {0}, execution time : {1}'.format(time.time(), time.time()-stime))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U63MP8HNGN7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    store_df_at_google_drive('task1_total_accuracy.csv'.format(title),acc_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZgmKMwToWO_v",
        "colab": {}
      },
      "source": [
        "# Table 3: Performance on Task 2\n",
        "\n",
        "drop_user_columns = ['Reputation', 'CreationDate', 'LastAccessDate']\n",
        "\n",
        "# model = LogisticRegression_\n",
        "# model = DecisionTreeClassifier\n",
        "models = [SVC_rbf, SVC_linear, DecisionTreeClassifier, LogisticRegression_]\n",
        "for i in range(len(models)):\n",
        "  model  = models[i]\n",
        "  for T in list_of_T:\n",
        "      stime=time.time()\n",
        "      print('Task 2, T={0}, start : {1}'.format(T, stime))\n",
        "      train_features = [col for col in features_of_task2[T].columns \n",
        "                        if col not in drop_user_columns + ['is_churn']]\n",
        "\n",
        "      acc_list = learn_model(features_of_task2[T], train_features, model=model)\n",
        "      print('Accuracy: {}'.format(np.mean(acc_list)))\n",
        "      print('    for each folds: {}'.format(acc_list))\n",
        "      print('end : {0}, execution time : {1}'.format(time.time(), time.time()-stime))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFM2c6IXaGGu",
        "colab": {}
      },
      "source": [
        "# Figure 5: Churn prediction accuracy when features from each category are used in isolation\n",
        "\n",
        "temporal_features = ['gap1', 'last_gap', 'time_since_last_post', 'mean_gap']\n",
        "frequency_features = ['num_answers', 'num_questions',\n",
        "                      'ans_que_ratio', 'num_posts']\n",
        "speed_features = ['answering_speed']\n",
        "quality_features = ['ans_score', 'que_score']\n",
        "consistency_features = ['ans_stddev', 'que_stddev']\n",
        "gratitude_features = ['ans_comments', 'que_comments']\n",
        "competitiveness_features = ['relative_rank_pos']\n",
        "content_features = ['ans_length', 'que_length']\n",
        "knowledge_features = ['accepted_answerer_rep', 'max_rep_answerer',\n",
        "                      'num_que_answered', 'time_for_first_ans',\n",
        "                      'rep_questioner', 'rep_answerers',\n",
        "                      'rep_co_answerers', 'num_answers_recvd']\n",
        "\n",
        "analysis_feature_names = {\n",
        "    'temporal': temporal_features,\n",
        "    'frequency': frequency_features,\n",
        "    'speed': speed_features,\n",
        "    'quality': quality_features,\n",
        "    'consistency': consistency_features,\n",
        "    'gratitude': gratitude_features,\n",
        "    'competitiveness': competitiveness_features,\n",
        "    'content': content_features,\n",
        "    'knowledge': knowledge_features,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ef5ac_2R1rPj",
        "colab": {}
      },
      "source": [
        "task1_accuracy_of_category = {}\n",
        "for name, feature_list in analysis_feature_names.items():\n",
        "    accuracy_of_category = []\n",
        "    for K in list_of_K:\n",
        "        if name == 'temporal':\n",
        "            feature_list = ['gap{}'.format(j) for j in range(1, K+1)]\n",
        "        elif name == 'frequency':\n",
        "            features_list = [feat for feat in feature_list if feat != 'num_posts']\n",
        "        train_features = [feat for feat in feature_list if feat in features_of_task1[K].columns]\n",
        "        if len(train_features) == 0:\n",
        "            continue\n",
        "        stime = time.time()\n",
        "        print('\\n{}, Task 1, K={}, start : {}'.format(name, K, stime))\n",
        "        print('    columns: {}'.format(train_features))\n",
        "         \n",
        "        acc_list = learn_model(features_of_task1[K], train_features)\n",
        "        mean_acc = np.mean(acc_list)\n",
        "        accuracy_of_category.append(mean_acc)\n",
        "        print('Accuracy: {}'.format(mean_acc))\n",
        "        print('    for each folds: {}'.format(acc_list))\n",
        "        print('end : {}, execution time : {}'.format(time.time(), time.time()-stime))\n",
        "    task1_accuracy_of_category[name] = accuracy_of_category"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ke9xkcjC9C3g",
        "colab": {}
      },
      "source": [
        "# Bar Chart\n",
        "for title, predictions in task1_accuracy_of_category.items():\n",
        "    if len(predictions) == 0:\n",
        "        continue\n",
        "    n_groups = len(list_of_K)\n",
        "    index = np.arange(n_groups)\n",
        "\n",
        "    plt.bar(index, predictions, tick_label=list_of_K, align='center')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlim(-1, n_groups)\n",
        "    plt.ylim(40, 100)\n",
        "    \n",
        "    plt.savefig('task1_{}_accuracy.png'.format(title))\n",
        "    plt.show()\n",
        "    store_df_at_google_drive('task1_{}_accuracy'.format(title),pd.DataFrame(),'png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p80eF9N6PYOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TU8JkA8k1t28",
        "colab": {}
      },
      "source": [
        "### Category Analysis - Task 2 ###\n",
        "task2_accuracy_of_category = {}\n",
        "for name, feature_list in analysis_feature_names.items():\n",
        "    accuracy_of_category = []\n",
        "    for T in list_of_T:\n",
        "        train_features = [feat for feat in feature_list if feat in features_of_task2[T].columns]\n",
        "        if len(train_features) == 0:\n",
        "            continue\n",
        "        stime = time.time()\n",
        "        print('\\n{}, Task 2, T={}, start : {}'.format(name, T, stime))\n",
        "        print('    columns: {}'.format(train_features))\n",
        "\n",
        "        acc_list = learn_model(features_of_task2[T], train_features)\n",
        "        mean_acc = np.mean(acc_list)\n",
        "        accuracy_of_category.append(mean_acc)\n",
        "        print('Accuracy: {}'.format(mean_acc))\n",
        "        print('    for each folds: {}'.format(acc_list))\n",
        "        print('end : {}, execution time : {}'.format(time.time(), time.time()-stime))\n",
        "\n",
        "    task2_accuracy_of_category[name] = accuracy_of_category"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r_4qFfOF1uHn",
        "colab": {}
      },
      "source": [
        "# Bar Chart\n",
        "for title, predictions in task2_accuracy_of_category.items():\n",
        "    if len(predictions) == 0:\n",
        "        continue\n",
        "    n_groups = len(list_of_T)\n",
        "    index = np.arange(n_groups)\n",
        "\n",
        "    plt.bar(index, predictions, tick_label=list_of_T, align='center')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlim(-1, n_groups)\n",
        "    plt.ylim(50, 80)\n",
        "    plt.savefig('task2_{}_accuracy.png'.format(title))\n",
        "    plt.show()\n",
        "    store_df_at_google_drive('task2_{}_accuracy'.format(title),pd.DataFrame(),'png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0lkszL557Csg",
        "colab": {}
      },
      "source": [
        "### Temporal Feature Analysis - Task 1 ###\n",
        "temporal_analysis_feature_func = {\n",
        "    'gapK': lambda K: ['gap{}'.format(j) for j in range(1, K+1)],\n",
        "    'last_gap': lambda K: ['gap{}'.format(K)]\n",
        "}\n",
        "\n",
        "\n",
        "task1_accuracy_with_time_gap = {}\n",
        "for K in list_of_K:\n",
        "    accuracy_with_time_gap = []\n",
        "    for name, feature_func in temporal_analysis_feature_func.items():\n",
        "        train_features = [feat for feat in feature_list if feat in features_of_task1[K].columns]\n",
        "        if len(train_features) == 0:\n",
        "            continue\n",
        "        stime = time.time()\n",
        "        print('\\n{}, Task 1, K={}, start : {}'.format(name, K, stime))\n",
        "        print('    columns: {}'.format(train_features))\n",
        "\n",
        "        acc_list = learn_model(features_of_task1[K], train_features)\n",
        "        mean_acc = np.mean(acc_list)\n",
        "        accuracy_with_time_gap.append(mean_acc)\n",
        "        print('Accuracy: {}'.format(mean_acc))\n",
        "        print('    for each folds: {}'.format(acc_list))\n",
        "        print('execution time : {}'.format(time.time()-stime))\n",
        "\n",
        "    task1_accuracy_with_time_gap[K] = accuracy_with_time_gap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yuFU5bd4_Efb",
        "colab": {}
      },
      "source": [
        "# Table 4: Temporal gap features analysis\n",
        "\n",
        "for K, acc in task1_accuracy_with_time_gap.items():\n",
        "    print(K, acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8stSxGNbNPo9",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}